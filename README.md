# RISK-MAP: A Comprehensive Framework for Robotics Security Assessment

[![DOI](https://img.shields.io/badge/DOI-10.xxxx%2Fxxxxxx-blue)](https://doi.org/10.xxxx/xxxxxx)
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)


> **Artifact Submission for USENIX Security 2026**  
> Paper Title: [Your Paper Title]  
> Authors: [Anonymous for Review]

## Abstract

RISK-MAP is a novel method for comprehensive security assessment of robotic systems across multiple architectural layers. This repository contains the complete implementation, datasets, and experimental artifacts supporting our USENIX Security 2025 submission.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Repository Structure](#repository-structure)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Detailed Usage](#detailed-usage)
- [Reproducing Paper Results](#reproducing-paper-results)
- [Dataset Description](#dataset-description)
- [Extending the Framework](#extending-the-framework)
- [Citation](#citation)
- [License](#license)

## ğŸ” Overview

The RISK-MAP framework provides:

- **Multi-layer Security Assessment**: Evaluates security across 7 robotic system layers
- **Quantitative Risk Scoring**: Generates numerical security scores for comparative analysis  
- **Visual Analytics**: Produces radar charts and heatmaps for intuitive risk visualization
- **Extensible Architecture**: Supports addition of new attack vectors and defense mechanisms
- **Empirical Validation**: Includes real-world case studies on commercial robotic platforms

### Key Features

- ğŸ›¡ï¸ **Comprehensive Coverage**: 39 attack vectors and 35 defense measures across Physical, Sensor & Perception, Data Processing, Middleware, Decision-Making, Application, and Social Interface layers
- ğŸ“Š **Quantitative Metrics**: Weighted risk scores with statistical validation
- ğŸ¯ **Practical Applicability**: Tested on 3 commercial robotic platforms
- ğŸ”§ **Automated Assessment**: Scriptable evaluation pipeline for CI/CD integration

## ğŸ“ Repository Structure
```
RISK_MAP/
â”œâ”€â”€ Information/                               # Robot descriptions and defense mappings
â”‚ â”œâ”€â”€ Description of Digit.xlsx                # High-level specification of Digit humanoid
â”‚ â”œâ”€â”€ Description of G1.xlsx                   # High-level specification of G1 EDU humanoid
â”‚ â”œâ”€â”€ Description of Pepper.xlsx               # High-level specification of Pepper humanoid
â”‚ â”œâ”€â”€ Digit defences.xlsx                      # Implemented defense mechanisms for Digit
â”‚ â”œâ”€â”€ G1 EDU defences.xlsx                     # Implemented defense mechanisms for G1 EDU
â”‚ â””â”€â”€ Pepper defences.xlsx                     # Implemented defense mechanisms for Pepper
â”‚
â”œâ”€â”€ data/ # Core inputs for RISK-MAP scoring
â”‚ â”œâ”€â”€ sensitivity/                             # Sensitivity analysis outputs
â”‚ â”‚ â”œâ”€â”€ sensitivity_Digit.csv                  # Sensitivity results for Digit
â”‚ â”‚ â”œâ”€â”€ sensitivity_G1_EDU.csv                 # Sensitivity results for G1 EDU
â”‚ â”‚ â”œâ”€â”€ sensitivity_Pepper.csv                 # Sensitivity results for Pepper
â”‚ â”‚ â””â”€â”€ table_sensitivity.csv                  # Consolidated sensitivity table
â”‚ â”‚
â”‚ â”œâ”€â”€ Digit_applicable_attacks.csv             # Attacks relevant to Digit
â”‚ â”œâ”€â”€ Digit_implementation_status.csv          # Defense implementation status for Digit
â”‚ â”œâ”€â”€ G1_EDU_applicable_attacks.csv            # Attacks relevant to G1 EDU
â”‚ â”œâ”€â”€ G1_EDU_implementation_status.csv         # Defense implementation status for G1 EDU
â”‚ â”œâ”€â”€ Pepper_applicable_attacks.csv            # Attacks relevant to Pepper
â”‚ â”œâ”€â”€ Pepper_implementation_status.csv         # Defense implementation status for Pepper
â”‚ â”œâ”€â”€ RISK_MAP_Per-Layer_Scores.csv            # Computed scores per OSI-like layer
â”‚ â”œâ”€â”€ attack_code_map.csv                      # Mapping of attack IDs to categories
â”‚ â”œâ”€â”€ attack_weights.csv                       # Weighting/severity factors per attack
â”‚ â””â”€â”€ attacks_vs_defenses_normalised.csv       # Normalised attackâ€“defense coverage matrix
â”‚
â”œâ”€â”€ figures/                                   # Generated plots and visualisations
â”‚ â”œâ”€â”€ Digit/
â”‚ â”‚ â”œâ”€â”€ heatmap.png                            # Top-10 residual risks (Digit)
â”‚ â”‚ â”œâ”€â”€ radar.pdf                              # 7-layer radar plot (Digit, PDF)
â”‚ â”‚ â””â”€â”€ radar.png                              # 7-layer radar plot (Digit, PNG)
â”‚ â”‚
â”‚ â”œâ”€â”€ G1_EDU/
â”‚ â”‚ â”œâ”€â”€ heatmap.png                            # Top-10 residual risks (G1 EDU)
â”‚ â”‚ â”œâ”€â”€ radar.pdf                              # 7-layer radar plot (G1 EDU, PDF)
â”‚ â”‚ â””â”€â”€ radar.png                              # 7-layer radar plot (G1 EDU, PNG)
â”‚ â”‚
â”‚ â”œâ”€â”€ Pepper/
â”‚ â”‚ â”œâ”€â”€ RISK_MAP_combined_radar.pdf            # Multi-robot radar (all three robots, PDF)
â”‚ â”‚ â”œâ”€â”€ RISK_MAP_combined_radar.png            # Multi-robot radar (PNG)
â”‚ â”‚ â”œâ”€â”€ combined_heatmap_safe_r.pdf            # Multi-robot heatmap (PDF)
â”‚ â”‚ â””â”€â”€ combined_heatmap_safe_r.png            # Multi-robot heatmap (PNG)
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ RISK_MAP_Assessment.ipynb                 # Main Jupyter notebook for reproduction
â”‚
â”œâ”€â”€ scripts/                                      # Python scripts for automated runs
â”‚ â”œâ”€â”€ combined_heatmap.py                         # Generate combined heatmaps across robots
â”‚ â”œâ”€â”€ heatmap.py                                  # Generate per-robot heatmaps
â”‚ â”œâ”€â”€ monte_carlo_RISK_MAP.py                     # Monte Carlo sensitivity analysis
â”‚ â”œâ”€â”€ score_RISK_MAP.py                           # Compute scores + per-layer radar plots
â”‚
â””â”€â”€ readme.md                                     # Repository guide (this file)
```

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- Git

### Option 1: Using pip (Recommended)

```bash
# Clone the repository
git clone https://github.com/anonymous4sc1ence/submission.git
cd submission

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

```
Option 2: Using conda
```
# Clone the repository
git clone https://github.com/anonymous4sc1ence/submission.git
cd submission

# Create conda environment
conda env create -f environment.yml
conda activate risk-map

```
Verify Installation
```
python scripts/score_RISK_MAP.py --help

```
âš¡ Quick Start
Basic Assessment

Run RISK-MAP assessment on all robots in the dataset:
```
python scripts/score_RISK_MAP.py

```
This will:

Process all *_implementation_status.csv files in data/

Generate individual radar charts in figures/[robot_name]/

Create per-layer scores in data/per_layer_scores.csv

Display summary results in the terminal

Generate Comparative Analysis

Create combined visualization comparing multiple robots:
```
python scripts/combined_radar.py

```
Expected Output
```
[âœ“]    Robot1: RISK_MAP  39.9%  â†’ figures/Robot1
[âœ“]    Robot2: RISK_MAP  48.9%  â†’ figures/Robot2  
[âœ“]    Robot3: RISK_MAP  79.5%  â†’ figures/Robot3
[âœ“] Wrote per-layer scores â†’ data/per_layer_scores.csv
[âœ“] Combined radar â†’ figures/combined_radar.pdf

```
ğŸ“– Detailed Usage
Assessing a New Robot

1. Create Implementation Status File:
```
cp data/template_implementation_status.csv data/my_robot_implementation_status.csv

```
2. Edit Defense Implementation Status:
3. Update the CSV with your robot's defense implementations (0.0 = not implemented, 1.0 = fully implemented)

Run Assessment:
```
python scripts/score_RISK_MAP.py --impl data/my_robot_implementation_status.csv

```
Custom Attack-Defense Matrix

To use your own attack-defense relationships:
```
python scripts/score_RISK_MAP.py --matrix path/to/custom_matrix.csv --weights path/to/custom_weights.csv

```
Advanced Analysis

For detailed layer-by-layer analysis:
```
from scripts.score_RISK_MAP import compute_scores
import pandas as pd

# Load data
A = pd.read_csv("data/attacks_vs_defenses_normalised.csv", index_col='Attack Vector')
W = pd.read_csv("data/attack_weights.csv", index_col='Attack Vector')['Weight']
I = pd.read_csv("data/robot_implementation_status.csv", index_col='Defence')['Implementation']

# Compute scores
overall, layer_scores, effectiveness_matrix = compute_scores(A, W, I)

print(f"Overall Security Score: {overall:.2f}")
for layer, score in layer_scores.items():
    print(f"{layer}: {score:.3f}")

```
# Reproducing Paper Results
Main Experimental Results (Section 5)
```


```
Expected runtime: ~5 minutes on standard desktop hardware.

ğŸ“Š Dataset Description
Core Datasets
| File                                 | Description                         | Dimensions               | Purpose                |
| ------------------------------------ | ----------------------------------- | ------------------------ | ---------------------- |
| `attacks_vs_defenses_normalised.csv` | Attack-defense effectiveness matrix | 39 attacks Ã— 35 defenses | Core assessment logic  |
| `attack_weights.csv`                 | Attack severity weights             | 39 attacks Ã— 1 weight    | Risk prioritization    |
| `*_implementation_status.csv`        | Robot defense implementations       | 35 defenses Ã— 1 status   | Individual assessments |

# Data Sources

Attack Vectors: Derived from systematic literature review of 89 robotics security papers (2015-2025)

Defense Mechanisms: Catalogued from commercial robotics frameworks and security standards

Effectiveness Ratings: Expert assessment validated through empirical testing

Severity Weights: Based on CVSS v3.1 and robotics-specific impact analysis

Data Quality Assurance

âœ… Inter-rater reliability: Îº = 0.82 (substantial agreement)

âœ… Coverage validation: 100% mapping to robotics security taxonomy

âœ… Consistency checks: Automated validation in tests/test_data_integrity.py

ğŸ“ˆ Performance and Scalability

Assessment Speed: ~0.1 seconds per robot on standard hardware
Memory Usage: <100MB for datasets with 1000+ robots
Scalability: Linear complexity O(n) for n robots
Parallel Processing: Built-in support for batch assessments

ğŸ“œ License
This project is licensed under the MIT License - see the LICENSE file for details.
```


